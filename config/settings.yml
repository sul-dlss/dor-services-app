# Feature flippers
enabled_features:
  registration: true
  create_ur_admin_policy: false
  datacite_update: false
  file_hierarchy_validation: true
  read_folio: true
  orcid_update: true
  shelve_to_purl_fetcher: false


# Ur Admin Policy
ur_admin_policy:
  druid: druid:hv992ry2431
  agreement: druid:wv961pm7301
  label: Ur-APO

# Stacks
stacks:
  document_cache_host: 'purl-test.stanford.edu'
  local_workspace_root: '/dor/workspace'
  local_stacks_root: '/stacks'
  local_document_cache_root: '/purl/document_cache'

# Suri
suri:
  url: 'https://suri.example.com'

# Workflow
workflow:
  logfile: 'log/workflow_service.log'
  shift_age: 'weekly'
  timeout: 60

version_service:
  # Turn sync_with_preservation to false in a testing environment where you don't
  # have a preservation-catalog container
  sync_with_preservation: true

# URLs
solr:
  select_path: 'select'
  timeout: 120
  url: 'https://solr.example.com/solr/collection'
dor_indexing:
  url: 'https://dor-indexing-app.example.edu/dor'
redis_url: 'redis://localhost:6379/'

workflow_url: 'https://workflow.example.com/workflow'
sdr:
  local_workspace_root: /dor/workspace
  local_export_home: /dor/export

rabbitmq:
  enabled: false
  hostname: localhost
  vhost: /
  username: guest
  password: guest

preservation_catalog:
  url: 'https://example.org/prescat'
  token: 'mint-token-with-target-preservation-catalog-rake-generate-token'
  read_timeout: 600

purl_fetcher:
  url: 'https://purl-fetcher.example.edu'
  token: 'fake-token'

# As of may 2024, this is just here to support auditing contents of
# technical-metadata-service. If the report that uses it (AuditTechnicalMetadataFileList)
# is removed, see whether this section can be removed.
technical_metadata:
  url: 'https://techmd-svc.example.edu'
  token: 'secret-token'

cleanup:
  local_workspace_root: '/dor/workspace'
  local_assembly_root: '/dor/assembly'
  local_export_home: '/dor/export'
  local_backup_path: /dor/stopped'

dor:
  hmac_secret: 'my$ecretK3y'

release:
  purl_base_url: 'https://purl.stanford.edu'

goobi:
  url: 'https://goobi-env.stanford.edu:9292/goobi/api/process/stanfordcreate?token=faketoken'
  dpg_workflow_name: 'goobiWF'
  default_goobi_workflow_name: 'Example_Workflow'
  max_tries: 3
  max_sleep_seconds: 20
  base_sleep_seconds: 2

catalog:
  symphony:
    base_url: "https://sirsi.example.com/symws/catalog/"
    barcode_path: "item/barcode/%{barcode}"
    headers:
      SD-ORIGINATING-APP-ID: DOR-SERVICES-APP
      SD-PREFERRED-ROLE: GUEST
  folio:
    okapi:
      url: "https://okapi-dev.example.com"
      username: "app_sdr"
      password: "supersecret"
      legacy_auth: true
    tenant_id: "example_tenant"
    max_lookup_tries: 5
    sleep_seconds: 10

datacite:
  prefix: '10.80343'
  host: fake.datacite.example.com

sidekiq:
  latency_threshold: 900 # number of seconds above which okcomputer check for sidekiq latency fails
                         # latency is expected to be temporarily big if lots of content is accessioned all at once
                         # see https://github.com/sidekiq/sidekiq/wiki/Monitoring#monitoring-queue-latency

honeybadger_checkins:
  embargo_release: foo
  missing_druids: bar

orcid:
  client_id: ~
  client_secret: ~
  base_url: https://api.sandbox.orcid.org
  base_public_url: https://pub.sandbox.orcid.org
  base_auth_url: https://sandbox.orcid.org

mais_orcid:
  client_id: ~
  client_secret: ~
  base_url: https://mais-sandbox.stanford.edu

rolling_indexer:
  # number of ids to get from Solr in a query
  query_size: 100
  # number of docs to send to Solr in a batch
  batch_size: 5
  # avoid overloading DSA for other work (seconds)
  pause_time_between_docs: 0.05
  # number of parallel processes to build solr docs from cocina
  num_parallel_processes: 1
  # a little more than softCommit max time is desired (a Solr 'add' with commitWithin does a softCommit) (seconds)
  # see solrconfig.xml for softCommit max time
  pause_for_solr: 61
  # milliseconds
  commitWithin: 500
