#!/usr/bin/env ruby
# frozen_string_literal: true

require_relative '../config/environment'
require_relative '../lib/fedora_cache'
require_relative '../lib/fedora_loader'
require_relative '../lib/data_error_notifier'
require 'set'
require 'optparse'
require 'diffy'
require 'dor/services/client'
require 'equivalent-xml'

options = { random: false, druids: [], fast: false }
parser = OptionParser.new do |option_parser|
  option_parser.banner = 'Usage: bin/validate-cocina-roundtrip [options]'

  option_parser.on('-sSAMPLE', '--sample SAMPLE', Integer, 'Sample size, otherwise all druids.')
  option_parser.on('-r', '--random', 'Select random druids.')
  option_parser.on('-dDRUIDS', '--druids DRUIDS', Array, 'List of druids (instead of druids.txt).')
  option_parser.on('-h', '--help', 'Displays help.') do
    puts option_parser
    exit
  end
end
parser.parse!(into: options)

cache = FedoraCache.new
loader = FedoraLoader.new(cache: cache)

Dor::Services::Client.configure(url: Settings.dor_services.url,
                                token: Settings.dor_services.token)

def write_result(druid, orig_cocina_hash, roundtrip_cocina_hash, diff_datastreams)
  File.open("results/#{druid}.txt", 'w') do |file|
    file.write("Druid: #{druid}\n\n")

    cocina_keys = (orig_cocina_hash.keys + roundtrip_cocina_hash.keys).uniq
    cocina_keys.each do |cocina_key|
      next if DeepEqual.match?(orig_cocina_hash[cocina_key], roundtrip_cocina_hash[cocina_key])

      file.write("Diff for #{cocina_key}:\n")
      file.write(Diffy::Diff.new("#{JSON.pretty_generate(orig_cocina_hash[cocina_key])}\n", "#{JSON.pretty_generate(roundtrip_cocina_hash[cocina_key])}\n"))
      file.write("\n\n")
    end

    diff_datastreams.each_pair do |dsid, ng_xmls|
      orig_ds_ng_xml, ds_ng_xml = ng_xmls

      file.write("Diff for #{dsid}:\n")
      file.write(Diffy::Diff.new("#{orig_ds_ng_xml.to_xml}\n", "#{ds_ng_xml.to_xml}\n"))
      file.write("\n\n")
    end
  end
end

def write_error(druid, error)
  File.open("results/#{druid}.txt", 'w') do |file|
    file.write("Druid: #{druid}\n\n")
    file.write("Error: #{error}\n\n")
    file.write("Backtrace:\n")
    file.write(error.backtrace.join("\n"))
    if error.cause
      file.write("\n\nCause:\n")
      file.write(error.cause.backtrace.join("\n"))
    end
  end
end

def ng_xml_for(xml)
  Nokogiri::XML(xml) { |config| config.default_xml.noblanks }
end

def validate_druid(druid, loader)
  return :missing unless loader.cached?(druid)

  begin
    fedora_obj = loader.load(druid)
  rescue FedoraLoader::BadCache
    write_error(druid, e)
    return :bad_cache
  rescue FedoraLoader::Unmapped
    return :unmapped
  end

  orig_datastreams = {}
  FedoraCache::DATASTREAMS.each { |dsid| orig_datastreams[dsid] = fedora_obj.datastreams[dsid]&.content }

  begin
    orig_cocina_obj = Cocina::Mapper.build(fedora_obj, notifier: DataErrorNotifier.new)
  rescue StandardError => e
    write_error(druid, e)
    return :mapping_error
  end

  orig_cocina_hash = orig_cocina_obj.to_h

  begin
    roundtrip_cocina_obj = Cocina::ObjectUpdater.run(fedora_obj, orig_cocina_obj, trial: true, notifier: DataErrorNotifier.new)
  rescue StandardError => e
    write_error(druid, e)
    return :update_error
  end
  roundtrip_cocina_hash = roundtrip_cocina_obj.to_h

  diff_datastreams = {}
  orig_datastreams.each_pair do |dsid, orig_datastream|
    next if orig_datastream.nil?

    orig_datastream_ng_xml = ng_xml_for(orig_datastream)

    datastream_ng_xml = ng_xml_for(fedora_obj.datastreams[dsid].content)
    next if EquivalentXml.equivalent?(orig_datastream_ng_xml, datastream_ng_xml, { element_order: false, normalize_whitespace: false })

    diff_datastreams[dsid] = [orig_datastream_ng_xml, datastream_ng_xml]
  end

  return :success if DeepEqual.match?(normalize_orig(orig_cocina_hash), normalize(roundtrip_cocina_hash))

  # && diff_datastreams.empty?
  # Currently only determining success based on cocina.
  # However, in future might want to also check datastreams. This would require normalization.

  write_result(druid, orig_cocina_hash, roundtrip_cocina_hash, diff_datastreams)
  :different
end

def normalize_orig(cocina_hash)
  # Remove space from source id, e.g., "sul: M0443_S2_D-K_B9_F33_011"
  source_id = cocina_hash.dig(:identification, :sourceId)
  cocina_hash[:identification][:sourceId] = source_id.gsub(/ *: */, ':') if source_id

  normalize(cocina_hash)
end

def normalize(cocina_hash)
  # Remove file and fileSet externalIdentifiers, since usually regenerated.
  Array(cocina_hash.dig(:structural, :contains)).each do |file_set|
    file_set.delete(:externalIdentifier)
    Array(file_set.dig(:structural, :contains)).each { |file| file.delete(:externalIdentifier) }
  end
  cocina_hash
end

def percentage(raw_num, denom)
  (100 * raw_num.to_f / denom).round(3)
end

unless options[:fast]
  FileUtils.rm_rf('results')
  FileUtils.mkdir_p('results')
end

if options[:druids].empty?
  druids = File.read('druids.txt').split
  druids.shuffle! if options[:random]
  druids = druids.take(options[:sample]) if options[:sample]
else
  druids = options[:druids]
end

results = Parallel.map(druids, progress: 'Testing') do |druid|
  validate_druid(druid, loader)
end
counts = { different: 0, success: 0, mapping_error: 0, update_error: 0, missing: 0, unmapped: 0, bad_cache: 0 }
results.each { |result| counts[result] += 1 }

denom = druids.size - counts[:missing] - counts[:unmapped] - counts[:bad_cache]

puts "Status (n=#{druids.size}; not using Missing for success/different/error stats):"
puts "  Success:   #{counts[:success]} (#{percentage(counts[:success], denom)}%)"
puts "  Different: #{counts[:different]} (#{percentage(counts[:different], denom)}%)"
puts "  Mapping error:     #{counts[:mapping_error]} (#{percentage(counts[:mapping_error], denom)}%)"
puts "  Update error:     #{counts[:update_error]} (#{percentage(counts[:update_error], denom)}%)"
puts "  Missing:     #{counts[:missing]} (#{(100 * counts[:missing].to_f / druids.size).round(3)}%)"
puts "  Unmapped:     #{counts[:unmapped]} (#{(100 * counts[:unmapped].to_f / druids.size).round(3)}%)"
puts "  Bad cache:     #{counts[:bad_cache]} (#{(100 * counts[:bad_cache].to_f / druids.size).round(3)}%)"
