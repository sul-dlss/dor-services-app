#!/usr/bin/env ruby
# frozen_string_literal: true

require_relative '../config/environment'
require_relative '../lib/fedora_cache'
require_relative '../lib/fedora_loader'
require_relative '../lib/data_error_notifier'
require 'set'
require 'optparse'
require 'diffy'
require 'dor/services/client'
require 'equivalent-xml'

options = { random: false, druids: [], fast: false, update: false, input: 'druids.txt' }
parser = OptionParser.new do |option_parser|
  option_parser.banner = 'Usage: bin/validate-cocina-roundtrip [options]'

  option_parser.on('-sSAMPLE', '--sample SAMPLE', Integer, 'Sample size, otherwise all druids.')
  option_parser.on('-u', '--update', 'Run object update instead of object create.')
  option_parser.on('-r', '--random', 'Select random druids.')
  option_parser.on('-f', '--fast', 'Without content metadata.')
  option_parser.on('-dDRUIDS', '--druids DRUIDS', Array, 'List of druids (instead of druids.txt).')
  option_parser.on('-iFILENAME', '--input FILENAME', String, 'File containing list of druids (instead of druids.txt).')
  option_parser.on('-h', '--help', 'Displays help.') do
    puts option_parser
    exit
  end
end
parser.parse!(into: options)

cache = FedoraCache.new
loader = FedoraLoader.new(cache: cache)

Dor::Services::Client.configure(url: Settings.dor_services.url,
                                token: Settings.dor_services.token)

# rubocop:disable Metrics/AbcSize
def write_result(druid, orig_cocina_hash, roundtrip_cocina_hash, diff_datastreams)
  File.open("results/#{druid}.txt", 'w') do |file|
    file.write("Druid: #{druid}\n\n")

    cocina_keys = (orig_cocina_hash.keys + roundtrip_cocina_hash.keys).uniq
    cocina_keys.each do |cocina_key|
      next if DeepEqual.match?(orig_cocina_hash[cocina_key], roundtrip_cocina_hash[cocina_key])

      file.write("Diff for #{cocina_key}:\n")
      file.write(Diffy::Diff.new("#{JSON.pretty_generate(orig_cocina_hash[cocina_key])}\n", "#{JSON.pretty_generate(roundtrip_cocina_hash[cocina_key])}\n"))
      file.write("\n\n")
    end

    diff_datastreams.each_pair do |dsid, ng_xmls|
      orig_datastream_ng_xml, norm_orig_datatream_ng_xml, roundtrip_datastream_ng_xml, norm_roundtrip_datastream_ng_xml = ng_xmls
      file.write("Difference found for #{dsid}\n")
      file.write("Diff for #{dsid}:\n")
      file.write(Diffy::Diff.new("#{norm_orig_datatream_ng_xml.to_xml}\n", "#{norm_roundtrip_datastream_ng_xml.to_xml}\n\n"))
      file.write("\nOriginal XML for #{dsid}:\n#{orig_datastream_ng_xml.to_xml}\n")
      file.write("\nNormalized original XML for #{dsid}:\n#{norm_orig_datatream_ng_xml.to_xml}\n") if orig_datastream_ng_xml != norm_orig_datatream_ng_xml
      file.write("\nRoundtripped XML for #{dsid}:\n#{roundtrip_datastream_ng_xml.to_xml}\n")
      file.write("\nNormalized roundtripped XML for #{dsid}:\n#{norm_roundtrip_datastream_ng_xml.to_xml}\n") if roundtrip_datastream_ng_xml != norm_roundtrip_datastream_ng_xml
      file.write("\n\n")
    end

    file.write("Original cocina:\n#{JSON.pretty_generate(orig_cocina_hash)}\n\n")
    file.write("Roundtrip cocina:\n#{JSON.pretty_generate(roundtrip_cocina_hash)}\n\n")
  end
end
# rubocop:enable Metrics/AbcSize

def write_error(druid, error)
  File.open("results/#{druid}.txt", 'w') do |file|
    file.write("Druid: #{druid}\n\n")
    file.write("Error: #{error}\n\n")
    file.write("Backtrace:\n")
    file.write(error.backtrace.join("\n"))
    if error.cause
      file.write("\n\nCause:\n")
      file.write(error.cause.backtrace.join("\n"))
    end
  end
end

def ng_xml_for(xml)
  Nokogiri::XML(xml) { |config| config.default_xml.noblanks }
end

def norm_orig_datastream_ng_xml_for(dsid, orig_datastream_ng_xml, druid, label, fedora_obj)
  case dsid
  # Additional normalizers to go here.
  when 'descMetadata'
    Cocina::Normalizers::ModsNormalizer.normalize(mods_ng_xml: orig_datastream_ng_xml, druid: druid, label: label)
  when 'rightsMetadata'
    Cocina::Normalizers::RightsNormalizer.normalize(datastream: fedora_obj.datastreams['rightsMetadata'])
  when 'contentMetadata'
    Cocina::Normalizers::ContentMetadataNormalizer.normalize(druid: druid, content_ng_xml: orig_datastream_ng_xml)
  when 'identityMetadata'
    Cocina::Normalizers::IdentityNormalizer.normalize(identity_ng_xml: orig_datastream_ng_xml)
  when 'embargoMetadata'
    Cocina::Normalizers::EmbargoNormalizer.normalize(embargo_ng_xml: orig_datastream_ng_xml)
  else
    orig_datastream_ng_xml
  end
end

def norm_roundtrip_datastream_ng_xml_for(dsid, roundtrip_datastream_ng_xml)
  case dsid
    # Additional normalizers to go here.
  when 'contentMetadata'
    Cocina::Normalizers::ContentMetadataNormalizer.normalize_roundtrip(content_ng_xml: roundtrip_datastream_ng_xml)
  else
    roundtrip_datastream_ng_xml
  end
end

def equivalent?(dsid, orig_datastream_ng_xml, roundtrip_ng_xml)
  if dsid == 'descMetadata'
    ModsEquivalentService.equivalent?(orig_datastream_ng_xml, roundtrip_ng_xml)
  else
    EquivalentXml.equivalent?(orig_datastream_ng_xml, roundtrip_ng_xml, { element_order: false, normalize_whitespace: false })
  end
end

def diff_datatreams_for(druid, label, orig_datastreams, fedora_obj)
  diff_datastreams = {}
  orig_datastreams.each_pair do |dsid, orig_datastream|
    next if orig_datastream.nil?

    orig_datastream_ng_xml = ng_xml_for(orig_datastream)
    norm_orig_datastream_ng_xml = norm_orig_datastream_ng_xml_for(dsid, orig_datastream_ng_xml, druid, label, fedora_obj)

    roundtrip_datastream_ng_xml = ng_xml_for(fedora_obj.datastreams[dsid].content)
    norm_roundtrip_datastream_ng_xml = norm_roundtrip_datastream_ng_xml_for(dsid, roundtrip_datastream_ng_xml)
    next if equivalent?(dsid, norm_orig_datastream_ng_xml, norm_roundtrip_datastream_ng_xml)

    diff_datastreams[dsid] = [orig_datastream_ng_xml, norm_orig_datastream_ng_xml, roundtrip_datastream_ng_xml, norm_roundtrip_datastream_ng_xml]
  end
  diff_datastreams
end

# rubocop:disable Metrics/AbcSize
# rubocop:disable Metrics/CyclomaticComplexity
# rubocop:disable Metrics/MethodLength
# rubocop:disable Metrics/PerceivedComplexity
def validate_druid(druid, loader, fast: false, create: false)
  return [druid, :missing] unless loader.cached?(druid)

  begin
    fedora_obj = loader.load(druid)
  rescue FedoraLoader::BadCache => e
    write_error(druid, e)
    return [druid, :bad_cache]
  rescue FedoraLoader::ExpectedUnmapped
    return [druid, :expected_unmapped]
  rescue FedoraLoader::Unmapped
    return [druid, :unmapped]
  end

  if fast && fedora_obj.datastreams.include?('contentMetadata')
    fedora_obj.contentMetadata.content = if create
                                           "<contentMetadata type='#{fedora_obj.contentMetadata.contentType.first}' objectId='#{druid}'/>"
                                         else
                                           "<contentMetadata type='#{fedora_obj.contentMetadata.contentType.first}' />"
                                         end
  end

  orig_datastreams = {}
  FedoraCache::DATASTREAMS.each { |dsid| orig_datastreams[dsid] = fedora_obj.datastreams[dsid]&.content }
  label = fedora_obj.label

  begin
    orig_cocina_obj = Cocina::Mapper.build(fedora_obj, notifier: DataErrorNotifier.new)
  rescue StandardError => e
    write_error(druid, e)
    return [druid, :mapping_error]
  end

  orig_cocina_hash = orig_cocina_obj.to_h

  if create
    begin
      roundtrip_fedora_obj, roundtrip_cocina_obj = Cocina::ObjectCreator.trial_create(orig_cocina_obj, notifier: DataErrorNotifier.new)
    rescue StandardError => e
      write_error(druid, e)
      return [druid, :create_error]
    end
    # RELS-EXT is not present in created Fedora object, so remove from orig_datastreams.
    orig_datastreams.delete('RELS-EXT')
  else
    begin
      roundtrip_cocina_obj = Cocina::ObjectUpdater.run(fedora_obj, orig_cocina_obj, trial: true, notifier: DataErrorNotifier.new)
      roundtrip_fedora_obj = fedora_obj
    rescue StandardError => e
      write_error(druid, e)
      return [druid, :update_error]
    end
  end
  roundtrip_cocina_hash = roundtrip_cocina_obj.to_h

  begin
    diff_datastreams = diff_datatreams_for(druid, label, orig_datastreams, roundtrip_fedora_obj)
  rescue StandardError => e
    write_error(druid, e)
    return [druid, :normalization_error]
  end

  return [druid, :success] if DeepEqual.match?(normalize_cocina(orig_cocina_hash), normalize_cocina(roundtrip_cocina_hash)) && diff_datastreams.empty?

  write_result(druid, orig_cocina_hash, roundtrip_cocina_hash, diff_datastreams)
  [druid, :different]
end
# rubocop:enable Metrics/AbcSize
# rubocop:enable Metrics/CyclomaticComplexity
# rubocop:enable Metrics/MethodLength
# rubocop:enable Metrics/PerceivedComplexity

def normalize_external_identifiers(cocina_hash)
  # Remove file and fileSet externalIdentifiers, since usually regenerated.
  Array(cocina_hash.dig(:structural, :contains)).each do |file_set|
    file_set.delete(:externalIdentifier)
    Array(file_set.dig(:structural, :contains)).each { |file| file.delete(:externalIdentifier) }
  end
  cocina_hash
end

def normalize_cocina(cocina_hash)
  normalize_external_identifiers(cocina_hash)
end

def percentage(raw_num, denom)
  (100 * raw_num.to_f / denom).round(3)
end

FileUtils.rm_rf('results')
FileUtils.mkdir_p('results')

if options[:druids].empty?
  druids = File.read(options[:input]).split
  druids.shuffle! if options[:random]
  druids = druids.take(options[:sample]) if options[:sample]
else
  druids = options[:druids]
end

results = Parallel.map(druids, progress: 'Testing') do |druid|
  validate_druid(druid, loader, fast: options[:fast], create: !options[:update])
end
counts = { different: 0, success: 0, mapping_error: 0, update_error: 0, create_error: 0, normalization_error: 0, missing: 0, unmapped: 0, expected_unmapped: 0, bad_cache: 0 }
File.open('results/results.txt', 'w') do |file|
  results.each do |druid, result|
    counts[result] += 1
    file.write("#{druid}=#{result}\n")
  end
end

denom = druids.size - counts[:missing] - counts[:unmapped] - counts[:expected_unmapped] - counts[:bad_cache]

puts "Status (n=#{druids.size}; not using Missing for success/different/error stats):"
puts "  Success:   #{counts[:success]} (#{percentage(counts[:success], denom)}%)"
puts "  Different: #{counts[:different]} (#{percentage(counts[:different], denom)}%)"
puts "  Mapping error:     #{counts[:mapping_error]} (#{percentage(counts[:mapping_error], denom)}%)"
if options[:update]
  puts "  Update error:     #{counts[:update_error]} (#{percentage(counts[:update_error], denom)}%)"
else
  puts "  Create error:     #{counts[:create_error]} (#{percentage(counts[:create_error], denom)}%)"
end
puts "  Normalization error:     #{counts[:normalization_error]} (#{percentage(counts[:normalization_error], denom)}%)"
puts "  Missing from cache:     #{counts[:missing]} (#{(100 * counts[:missing].to_f / druids.size).round(3)}%)"
puts "  Unmapped:     #{counts[:unmapped]} (#{(100 * counts[:unmapped].to_f / druids.size).round(3)}%)"
puts "  Expected unmapped:     #{counts[:expected_unmapped]} (#{(100 * counts[:expected_unmapped].to_f / druids.size).round(3)}%)"
puts "  Bad cache:     #{counts[:bad_cache]} (#{(100 * counts[:bad_cache].to_f / druids.size).round(3)}%)"
